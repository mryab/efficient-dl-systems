{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1d86fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "\n",
    "vgg16 = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630b93e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = torch.rand(1, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb68423",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(vgg16, example, \"vgg16.onnx\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8776de8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! head vgg16.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f7076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install onnx\n",
    "! pip install tensorflow\n",
    "! pip install tensorflow-addons\n",
    "! pip install onnx_tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7db2e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx_tf.backend import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd6fd9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-26 14:49:23.572426: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = onnx.load('vgg16.onnx')\n",
    "tf_rep = prepare(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcd62529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-02-26 14:49:38--  https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg/1200px-Cat03.jpg\n",
      "Распознаётся upload.wikimedia.org (upload.wikimedia.org)… 91.198.174.208\n",
      "Подключение к upload.wikimedia.org (upload.wikimedia.org)|91.198.174.208|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 156145 (152K) [image/jpeg]\n",
      "Сохранение в: «1200px-Cat03.jpg.1»\n",
      "\n",
      "1200px-Cat03.jpg.1  100%[===================>] 152,49K  --.-KB/s    за 0,1s    \n",
      "\n",
      "2022-02-26 14:49:39 (1,08 MB/s) - «1200px-Cat03.jpg.1» сохранён [156145/156145]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg/1200px-Cat03.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "802caa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform_pipeline = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "def prepare(img_path):\n",
    "    image = Image.open(img_path)\n",
    "    img_data = transform_pipeline(image).unsqueeze(0)\n",
    "    data = np.array(img_data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9e019ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "img = prepare('1200px-Cat03.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9497721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8202c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tf_rep.run(np.asarray(img, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdd193cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6200f32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `__call__` contains input name(s) input.1 with unsupported characters which will be renamed to input_1 in the SavedModel.\n",
      "2022-02-26 14:50:34.156599: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vgg16.pb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vgg16.pb/assets\n"
     ]
    }
   ],
   "source": [
    "tf_rep.export_graph('vgg16.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aa848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbe8e5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34massets\u001b[m\u001b[m         saved_model.pb \u001b[34mvariables\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "! ls vgg16.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "446b6d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47f022d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltf = tf.saved_model.load(\"vgg16.pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "915777d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject at 0x171f55280>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeltf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5eac4afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer = modeltf.signatures[\"serving_default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e38c7a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 224, 224), dtype=float32, numpy=\n",
       "array([[[[1.5981677 , 1.6324171 , 1.6837914 , ..., 1.8379141 ,\n",
       "          1.8550389 , 1.8550389 ],\n",
       "         [1.5981677 , 1.6324171 , 1.6837914 , ..., 1.8721637 ,\n",
       "          1.8892884 , 1.8892884 ],\n",
       "         [1.5981677 , 1.6324171 , 1.6837914 , ..., 1.9064132 ,\n",
       "          1.9064132 , 1.8892884 ],\n",
       "         ...,\n",
       "         [1.1015497 , 1.1357993 , 1.0844251 , ..., 1.6324171 ,\n",
       "          1.6324171 , 1.6152923 ],\n",
       "         [1.1186745 , 1.1529241 , 1.1015497 , ..., 1.6837914 ,\n",
       "          1.6837914 , 1.6837914 ],\n",
       "         [1.0501755 , 1.0844251 , 1.0844251 , ..., 1.7180408 ,\n",
       "          1.7180408 , 1.7351656 ]],\n",
       "\n",
       "        [[1.6232493 , 1.6757703 , 1.7457983 , ..., 1.8858544 ,\n",
       "          1.8683473 , 1.8508403 ],\n",
       "         [1.6057423 , 1.6757703 , 1.7457983 , ..., 1.8858544 ,\n",
       "          1.8858544 , 1.8508403 ],\n",
       "         [1.6407562 , 1.7107843 , 1.7633053 , ..., 1.8858544 ,\n",
       "          1.8508403 , 1.7983193 ],\n",
       "         ...,\n",
       "         [0.71288526, 0.76540625, 0.69537824, ..., 1.5707283 ,\n",
       "          1.5882353 , 1.5707283 ],\n",
       "         [0.74789923, 0.78291327, 0.7303922 , ..., 1.6232493 ,\n",
       "          1.6407562 , 1.6407562 ],\n",
       "         [0.6778712 , 0.71288526, 0.71288526, ..., 1.6582633 ,\n",
       "          1.6757703 , 1.6932774 ]],\n",
       "\n",
       "        [[1.2805231 , 1.4025275 , 1.5071026 , ..., 1.8731157 ,\n",
       "          1.8556864 , 1.8556864 ],\n",
       "         [1.2282355 , 1.367669  , 1.4896734 , ..., 1.8905448 ,\n",
       "          1.8905448 , 1.8556864 ],\n",
       "         [1.2108063 , 1.3502399 , 1.4722441 , ..., 1.8905448 ,\n",
       "          1.8556864 , 1.8208281 ],\n",
       "         ...,\n",
       "         [0.2696297 , 0.32191727, 0.2696297 , ..., 1.5071026 ,\n",
       "          1.5245317 , 1.5071026 ],\n",
       "         [0.33934647, 0.37420484, 0.32191727, ..., 1.5593902 ,\n",
       "          1.5768193 , 1.5768193 ],\n",
       "         [0.3044881 , 0.33934647, 0.32191727, ..., 1.5942485 ,\n",
       "          1.6116778 , 1.6291069 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14edde30",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = infer(tf.constant(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97fca4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = next(iter(output.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05c5c96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb0ec8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
